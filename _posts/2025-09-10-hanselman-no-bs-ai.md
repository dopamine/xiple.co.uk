---
layout: post
title:  "Scott Hanselman’s takes on no-BS AI"

coverimg: 20XX-XX-XX-folder/image
---

Smashing Magazine did a 3-session special on AI that this was part of, here’s the [playlist](https://www.youtube.com/playlist?list=PLxQqv_fazRs1VlMEbqC0Jlw6VFd97UpT2). A lot of [Scott’s talk](https://www.youtube.com/watch?v=xMM4JP3V-OA&list=PLxQqv_fazRs1VlMEbqC0Jlw6VFd97UpT2&index=2&ab_channel=SmashingMagazine) is more nerdy but here’s a couple of useful soundbites, somewhat paraphrased by me:

> We’re anthropomorphising AI, pretending it’s magic or a black box. It’s worth understanding a bit more about how it works under the hood, because it will give us a healthier relationship with what’s going on.

 

On AI “smartness” and the effects/limitations of training:

> When you take a million monkeys and a million typewriters and they all slap the keyboard, eventually Shakespeare pops out. That's math. […But] when the parrot that lives at your aunt house swears at you, that's  not because the parrot is smart. That's because your aunt swears.

> Why do models not say “I don’t know” when they doesn’t know? That’s because those types of conversations aren’t in their training data. They’re trained on example conversations that answer questions with confidence, so they ape that behaviour even in conversations when they don’t know.